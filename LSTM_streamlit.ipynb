{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1669f032-030f-437c-9663-4b5f4e86c1e6",
   "metadata": {},
   "source": [
    "# Неделя 7: обработка естесственного языка \n",
    "\n",
    "## Классификация отзывов с помощью рекуррентных нейронных сетей"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3d41cc-abd7-4951-ac39-6a09c09496ab",
   "metadata": {},
   "source": [
    "#### В сегодняшнем задании необходимо классифицировать [отзывы]((https://www.kaggle.com/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews)) с сайта IMDB  и сравнить полученный результат со вчерашним (когда классификация проходила с помощью классических алгоритмов). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2727571a-e850-4457-a2e9-d4feb5a3154d",
   "metadata": {},
   "source": [
    "Загрузи датасет, задай модель и попробуй улучшить результат, который был получен вчера. Для корректной обработки текста необходимо его представить в виде последовательности индексов, которую нужно пропустить через слой `Embedding`. \n",
    "\n",
    "* [документация](https://keras.io/api/layers/core_layers/embedding/) по слою в `keras`\n",
    "* [документация](https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html) по слою в `pyTorch`\n",
    "\n",
    "Если будешь использовать `pyTorch`, то можно применить `torchtext`: относительно новая библиотека для работы с текстом в `pyTorch`-стиле. Например, там есть собственный [токенизатор](https://pytorch.org/text/stable/data_utils.html#get-tokenizer): `get_tokenizer`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7bd4597-3615-483c-bf42-459b9922bbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# импортируй библиотеки \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# natural language toolkit \n",
    "import nltk\n",
    "\n",
    "# regular expression\n",
    "import re\n",
    "\n",
    "import string\n",
    "\n",
    "import tqdm\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from collections import Counter\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d49944f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import RegexpTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0abe263e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "\n",
    "from torchsummary import summary\n",
    "from torchmetrics import MeanSquaredError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df8962f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class sentimentLSTM(nn.Module):\n",
    "    \"\"\"\n",
    "    The RNN model that will be used to perform Sentiment analysis.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self,\n",
    "                 vocab_size, # объём словаря с которым мы работаем\n",
    "                 output_size, # нейроны полносвязного\n",
    "                 embedding_dim, # размер выходного эмбеддинга\n",
    "                 hidden_dim, # размерность внутреннего слоя LSTM\n",
    "                 n_layers, # число слоев в LSTM\n",
    "                 drop_prob=0.5):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.output_size = output_size\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "        # nn.Linear(64, 16) / embedding_dim - выходная размерность \n",
    "        self.lstm = nn.LSTM(embedding_dim, \n",
    "                            hidden_dim, \n",
    "                            n_layers, \n",
    "                            dropout=drop_prob, \n",
    "                            batch_first=True)\n",
    "        \n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        \n",
    "        self.fc = nn.Linear(hidden_dim, output_size)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x, hidden):\n",
    "\n",
    "        batch_size = x.size(0)\n",
    "        \n",
    "        embeds = self.embedding(x)\n",
    "        # print(f'Embed shape: {embeds.shape}')\n",
    "        lstm_out, hidden = self.lstm(embeds, hidden)\n",
    "        # print(f'lstm_out {lstm_out.shape}')\n",
    "        # print(f'hidden {hidden[0].shape}')\n",
    "        # print(f'hidden {hidden[1].shape}')\n",
    "        #stack up lstm outputs\n",
    "        lstm_out = lstm_out.contiguous().view(-1, self.hidden_dim)\n",
    "        # print(f'lstm out after contiguous: {lstm_out.shape}')\n",
    "        # Dropout and fully connected layer\n",
    "        out = self.dropout(lstm_out)\n",
    "        out = self.fc(out)\n",
    "        \n",
    "        #sigmoid function\n",
    "        sig_out = self.sigmoid(out)\n",
    "        \n",
    "        # reshape to be batch size first\n",
    "        # print(sig_out.shape)\n",
    "        sig_out = sig_out.view(batch_size, -1)\n",
    "        # print(sig_out.shape)\n",
    "        # print(f'Sig out before indexing:{sig_out.shape}')\n",
    "        sig_out = sig_out[:, -1] # get last batch of labels\n",
    "        # print(sig_out.shape)\n",
    "        \n",
    "        return sig_out, hidden\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        ''' Hidden state и Cell state инициализируем нулями '''\n",
    "\n",
    "        h0 = torch.zeros((self.n_layers,batch_size,self.hidden_dim)).to(device)\n",
    "        c0 = torch.zeros((self.n_layers,batch_size,self.hidden_dim)).to(device)\n",
    "        hidden = (h0,c0)\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69669cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_loaded = sentimentLSTM(161203, 1, 32, 16, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd5a121b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_loaded.load_state_dict(torch.load('state_dict.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "522585ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb110d9b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/dbushuev/NLP_streamlit_GPT_QA/LSTM_streamlit.ipynb Ячейка 10\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/dbushuev/NLP_streamlit_GPT_QA/LSTM_streamlit.ipynb#Y110sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m test_h1 \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39minit_hidden(\u001b[39m1\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/dbushuev/NLP_streamlit_GPT_QA/LSTM_streamlit.ipynb#Y110sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m# print(test_h1)\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/dbushuev/NLP_streamlit_GPT_QA/LSTM_streamlit.ipynb#Y110sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m model_loaded\u001b[39m.\u001b[39meval()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "test_h1 = model.init_hidden(1)\n",
    "# print(test_h1)\n",
    "\n",
    "model_loaded.eval()\n",
    "# for inputs, labels in test_loader:\n",
    "    #     print(inputs)\n",
    "test_h = tuple([each.data for each in test_h1])\n",
    "\n",
    "inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "output, test_h = model(for_pred, test_h)\n",
    "\n",
    "# test_loss = criterion(output.squeeze(), labels.float())\n",
    "# test_losses.append(test_loss.item())\n",
    "# sm = torch.nn.Softmax()\n",
    "\n",
    "pred = output.squeeze()\n",
    "print(pred, pred.shape)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "a2506d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import csv\n",
    "\n",
    "def LSTMpred(str: str):\n",
    "    df = pd.DataFrame(pd.Series(str, name='review'))\n",
    "    # print(df)\n",
    "    def clean(text):\n",
    "        text = text.lower() # нижний регистр\n",
    "        # text = re.sub(r'http\\S+', \" \", text) # удаляем ссылки\n",
    "        # text = re.sub(r'@\\w+',' ',text) # удаляем упоминания пользователей\n",
    "        # text = re.sub(r'#\\w+', ' ', text) # удаляем хэштеги\n",
    "        text = re.sub(r'\\d+', ' ', text) # удаляем числа\n",
    "        text = re.sub(r'<.*?>',' ', text) # \n",
    "        text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "        \n",
    "        return text\n",
    "    \n",
    "    df['review'] = df['review'].apply(clean)\n",
    "\n",
    "    wn_lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    lemmatized_text = []\n",
    "\n",
    "    for review in df['review']:\n",
    "        lemmatized_text.append(' '.join([wn_lemmatizer.lemmatize(word, 'a') for word in review.split()]))\n",
    "\n",
    "    reg_tokenizer = RegexpTokenizer('\\w+')\n",
    "    \n",
    "    tokenized_text = reg_tokenizer.tokenize_sents(lemmatized_text)\n",
    "    sw = stopwords.words('english')\n",
    "    # print(sw)\n",
    "    clean_tokenized_reviews = [] \n",
    "    for i, element in tqdm(enumerate(tokenized_text), total=len(tokenized_text)):\n",
    "        clean_tokenized_reviews.append(' '.join([word for word in element if word not in sw]))\n",
    "    df['review'] = pd.Series(clean_tokenized_reviews)\n",
    "    # print(df)\n",
    "\n",
    "    \n",
    "    corpus = [word for text in df['review'] for word in text.split()]\n",
    "    count_words = Counter(corpus)\n",
    "    sorted_words = count_words.most_common()\n",
    "\n",
    "    \n",
    "\n",
    "    with open('vocab.csv', mode='r') as infile:\n",
    "        reader = csv.reader(infile)\n",
    "        # print(reader)\n",
    "        with open('coors_new.csv', mode='w') as outfile:\n",
    "            writer = csv.writer(outfile)\n",
    "            vocab_to_int = {rows[0]:rows[1] for rows in reader}\n",
    "    \n",
    "    reviews_int = []\n",
    "    for text in df['review']:\n",
    "        # print(text)\n",
    "        r = [int(vocab_to_int[word]) for word in text.split() if word in vocab_to_int.keys()]\n",
    "       \n",
    "        reviews_int.append(r)\n",
    "\n",
    "    def padding(review_int, seq_len):\n",
    "        '''\n",
    "        Делаем padding, если длинна меньше seq_len, \n",
    "        если больше – берем первые seq_len индексов\n",
    "        '''\n",
    "        features1 = np.zeros((len(reviews_int), seq_len), dtype = int)\n",
    "        for i, review in enumerate(review_int):\n",
    "            if len(review) <= seq_len:\n",
    "                zeros = list(np.zeros(seq_len - len(review)))\n",
    "                new = zeros + review\n",
    "            else:\n",
    "                new = review[: seq_len]\n",
    "            # print(i, new)\n",
    "            features1[i, :] = np.array(new)\n",
    "                \n",
    "        return features1\n",
    "    features = padding(reviews_int, seq_len = 50)\n",
    "    return np.array(features)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.03514909744262695,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 1,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "201bda426c694ac7a5f4f557ed6cf859",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[  134,  1103,   178,  2209,    91,   560,    45,  1263,   230,\n",
       "        21148,  2107, 20868,  4166,   178,   279,   218,  2878,  2761,\n",
       "          128,     4,   105, 10608,   166,  1263,  3183,  5634,   250,\n",
       "          369,   502,   718,   662,  1454,  4697,  3584,  1013,   256,\n",
       "        11704,   301,    49,   124,   794,   516, 16499,   908,  6357,\n",
       "          275, 11222,  7832,   811,   341]])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for_pred = LSTMpred(\"Last week, I watched seasons 1-7 of GoT so those episodes are still very fresh in my mind and I am unaffected by rose tinted nostalgia. I have just watched episode 1 of House of the Dragon. How can I sum it up? So far, so good. The music is sufficiently different to be fresh while remaining recognizable. The production quality and cinematography are as expected - fantastic, epic and awe inspiring, aside from a couple of excessively dark scenes that were over and done with very quickly. There is gore aplenty. Nudity, vomit, sex and depravity. Incidental background humor. A promise of things to come. The casting seems to be on point - I saw no issue with any of the characters, and the leads were well chosen for their roles. The writing seems to be up to par. As an introduction, this episode was written and directed well. I want to see and know more - a good sign. So far I am pleased with this return to the land of Westeros. Valar morghulis!\")\n",
    "for_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "5b0daccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_h1 = model_loaded.init_hidden(1)\n",
    "# print(test_h1)\n",
    "\n",
    "model_loaded.eval()\n",
    "# for inputs, labels in test_loader:\n",
    "    #     print(inputs)\n",
    "test_h = tuple([each.data for each in test_h1])\n",
    "\n",
    "# inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "output, test_h = model_loaded(torch.tensor(for_pred), test_h)\n",
    "\n",
    "# test_loss = criterion(output.squeeze(), labels.float())\n",
    "# test_losses.append(test_loss.item())\n",
    "# sm = torch.nn.Softmax()\n",
    "\n",
    "pred = float(output.squeeze().detach().numpy())\n",
    "# print(pred, pred.shape)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "c11c8cbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9733338952064514"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "4ebbe7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = {'Positive': f'{format(pred*100, \".2f\")} %', 'Negative': f'{format((1-pred)*100, \".2f\")} %' }\n",
    "out_stl = pd.DataFrame(output, index=['Probability'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "1011a244",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Positive</th>\n",
       "      <th>Negative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Probability</th>\n",
       "      <td>97.33 %</td>\n",
       "      <td>2.67 %</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Positive Negative\n",
       "Probability  97.33 %   2.67 %"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_stl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4512f565",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040b6cd4-c6ac-4d2f-bf4c-36cf2cb26d86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7e349e12-7a28-465b-b8ee-4a2b247e0a9a",
   "metadata": {},
   "source": [
    "##### Сформируй датафрейм, в котором по строкам будут расположены названия обученных моделей, а по столбцам значение метрики на валидации. \n",
    "\n",
    "|model_arch | val_accuracy |val_loss|\n",
    "|-----------|:------------:|:------:|\n",
    "|SimpleRNN  | ...          |...|\n",
    "|LSTM       |     ...      |...|\n",
    "|BiLSTM     | ...          |...|\n",
    "|GRU        |  ...         |...|\n",
    "|...        |...           |...|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0680eafe-af1f-4934-b443-2aecbe61b6bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "331bbf61-1b0c-4ea4-bf4e-ef90b6288562",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Вопросы\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7425afb-ae7a-48a3-95b9-e292e863f27f",
   "metadata": {},
   "source": [
    "1. Засчет чего (кроме увеличения длины последовательности) можно улучшить модель?\n",
    "\n",
    "> ответ тут\n",
    "\n",
    "2. Какую предобработку применять? Нужно ли, например, удалять стоп-слова, как мы делали вчера? А знаки препинания? Объясни свой ответ. \n",
    "\n",
    "> ответ тут\n",
    "\n",
    "3. Какова структура отзыва на фильм? Какая часть рецензии, как правило, выражает отношение пользователя к фильму? Что можно сделать, чтобы увеличить качество модели с учетом твоих предположений?\n",
    "\n",
    "> ответ тут"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('neiro')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "ff077d36edecff411963b88ef1bfe99368317a6b3a0d3848dbdbf2bfef07112c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
