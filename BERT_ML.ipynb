{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.22.0-py3-none-any.whl (4.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting filelock\n",
      "  Downloading filelock-3.8.0-py3-none-any.whl (10 kB)\n",
      "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
      "  Downloading tokenizers-0.12.1-cp310-cp310-macosx_10_11_x86_64.whl (3.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /Users/dbushuev/miniforge3/envs/neiro/lib/python3.10/site-packages (from transformers) (2022.9.13)\n",
      "Requirement already satisfied: requests in /Users/dbushuev/miniforge3/envs/neiro/lib/python3.10/site-packages (from transformers) (2.28.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/dbushuev/miniforge3/envs/neiro/lib/python3.10/site-packages (from transformers) (1.23.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/dbushuev/miniforge3/envs/neiro/lib/python3.10/site-packages (from transformers) (21.3)\n",
      "Collecting huggingface-hub<1.0,>=0.9.0\n",
      "  Downloading huggingface_hub-0.9.1-py3-none-any.whl (120 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m120.7/120.7 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /Users/dbushuev/miniforge3/envs/neiro/lib/python3.10/site-packages (from transformers) (4.64.0)\n",
      "Collecting pyyaml>=5.1\n",
      "  Downloading PyYAML-6.0-cp310-cp310-macosx_10_9_x86_64.whl (197 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m197.6/197.6 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /Users/dbushuev/miniforge3/envs/neiro/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.9.0->transformers) (4.3.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Users/dbushuev/miniforge3/envs/neiro/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.0.9)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/dbushuev/miniforge3/envs/neiro/lib/python3.10/site-packages (from requests->transformers) (1.26.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/dbushuev/miniforge3/envs/neiro/lib/python3.10/site-packages (from requests->transformers) (2022.6.15)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/dbushuev/miniforge3/envs/neiro/lib/python3.10/site-packages (from requests->transformers) (3.3)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/dbushuev/miniforge3/envs/neiro/lib/python3.10/site-packages (from requests->transformers) (2.1.1)\n",
      "Installing collected packages: tokenizers, pyyaml, filelock, huggingface-hub, transformers\n",
      "Successfully installed filelock-3.8.0 huggingface-hub-0.9.1 pyyaml-6.0 tokenizers-0.12.1 transformers-4.22.0\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving 0 files to the new cache system\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.055795907974243164,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 0,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86e897e331f64089b1d78336f0acadf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.023472070693969727,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading",
       "rate": null,
       "total": 231508,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "710d0c9a67344e1fac393fe54f3c58ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.024684906005859375,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading",
       "rate": null,
       "total": 28,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9984fae9b374d9e8855b6b1491fdb75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.02841806411743164,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading",
       "rate": null,
       "total": 483,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25516822d6094c7f959768a150de21da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/483 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.02594780921936035,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading",
       "rate": null,
       "total": 267967963,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "614f8d8043db4528ae0a5fb0bc3a1964",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# DistilBERT:\n",
    "\n",
    "## задаем саму модель\n",
    "model_class = transformers.DistilBertModel\n",
    "\n",
    "## токенайзер к ней (для некоторых моделей токенайзер будет отличаться, см.\n",
    "## в документации к каждой модели конкретно)\n",
    "tokenizer_class = transformers.DistilBertTokenizer\n",
    "\n",
    "## загружаем веса для моделей\n",
    "pretrained_weights = 'distilbert-base-uncased'\n",
    "\n",
    "\n",
    "\n",
    "# AlBERT:\n",
    "# model_class, tokenizer_class, pretrained_weights = (transformers.AlbertModel, \n",
    "#                                                     transformers.AlbertTokenizerFast,\n",
    "#                                                     'albert-base-v1')\n",
    "\n",
    "# BERT\n",
    "# model_class, tokenizer_class, pretrained_weights = (transformers.BertModel, \n",
    "#                                                     transformers.BertTokenizer, \n",
    "#                                                     'bert-base-uncased')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "###########################################\n",
    "# создаем объекты токенизатора для и модели\n",
    "tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
    "model = model_class.from_pretrained(pretrained_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(pd.Series(\"Last week, I watched seasons 1-7 of GoT so those episodes are still very fresh in my mind and I am unaffected by rose tinted nostalgia. I have just watched episode 1 of House of the Dragon. How can I sum it up? So far, so good. The music is sufficiently different to be fresh while remaining recognizable. The production quality and cinematography are as expected - fantastic, epic and awe inspiring, aside from a couple of excessively dark scenes that were over and done with very quickly. There is gore aplenty. Nudity, vomit, sex and depravity. Incidental background humor. A promise of things to come. The casting seems to be on point - I saw no issue with any of the characters, and the leads were well chosen for their roles. The writing seems to be up to par. As an introduction, this episode was written and directed well. I want to see and know more - a good sign. So far I am pleased with this return to the land of Westeros. Valar morghulis!\", name = 'review'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Last week, I watched seasons 1-7 of GoT so tho...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review\n",
       "0  Last week, I watched seasons 1-7 of GoT so tho..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized = df['review'].apply((lambda x: tokenizer.encode(x, add_special_tokens=True, \n",
    "                                                                      truncation=True, \n",
    "                                                                      max_length=max_len)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [101, 2197, 2733, 1010, 1045, 3427, 3692, 1015...\n",
       "Name: review, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "padded = np.array([i + [0]*(max_len-len(i)) for i in tokenized.values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_mask = np.where(padded != 0, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = torch.tensor(padded)  \n",
    "attention_mask = torch.tensor(attention_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  101,  2197,  2733,  1010,  1045,  3427,  3692,  1015,  1011,  1021,\n",
       "          1997,  2288,  2061,  2216,  4178,  2024,  2145,  2200,  4840,  1999,\n",
       "          2026,  2568,  1998,  1045,  2572, 24720,  2011,  3123, 25577, 26968,\n",
       "          1012,  1045,  2031,  2074,  3427,  2792,  1015,  1997,  2160,  1997,\n",
       "          1996,  5202,  1012,  2129,  2064,  1045,  7680,  2009,  2039,  1029,\n",
       "          2061,  2521,  1010,  2061,  2204,  1012,  1996,  2189,  2003, 12949,\n",
       "          2367,  2000,  2022,  4840,  2096,  3588, 20123,  1012,  1996,  2537,\n",
       "          3737,  1998, 16434,  2024,  2004,  3517,  1011, 10392,  1010,  8680,\n",
       "          1998, 15180, 18988,  1010,  4998,  2013,  1037,  3232,  1997, 11664,\n",
       "          2135,  2601,  5019,  2008,  2020,  2058,  1998,  2589,  2007,   102]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.inference_mode():\n",
    "    last_hidden_states = model(input_ids, attention_mask=attention_mask)\n",
    "\n",
    "features = last_hidden_states[0][:,0,:].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 768)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dbushuev/miniforge3/envs/neiro/lib/python3.10/site-packages/sklearn/base.py:329: UserWarning: Trying to unpickle estimator LogisticRegression from version 1.0.2 when using version 1.1.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "\n",
    "lr = joblib.load('LReg.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.02422911, 0.97577089]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.predict_proba(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting catboost\n",
      "  Using cached catboost-1.0.6-cp310-none-macosx_10_6_universal2.whl (22.0 MB)\n",
      "Requirement already satisfied: numpy>=1.16.0 in /Users/dbushuev/miniforge3/envs/neiro/lib/python3.10/site-packages (from catboost) (1.23.2)\n",
      "Collecting graphviz\n",
      "  Using cached graphviz-0.20.1-py3-none-any.whl (47 kB)\n",
      "Collecting plotly\n",
      "  Using cached plotly-5.10.0-py2.py3-none-any.whl (15.2 MB)\n",
      "Requirement already satisfied: six in /Users/dbushuev/miniforge3/envs/neiro/lib/python3.10/site-packages (from catboost) (1.16.0)\n",
      "Requirement already satisfied: scipy in /Users/dbushuev/miniforge3/envs/neiro/lib/python3.10/site-packages (from catboost) (1.9.1)\n",
      "Requirement already satisfied: matplotlib in /Users/dbushuev/miniforge3/envs/neiro/lib/python3.10/site-packages (from catboost) (3.5.3)\n",
      "Requirement already satisfied: pandas>=0.24.0 in /Users/dbushuev/miniforge3/envs/neiro/lib/python3.10/site-packages (from catboost) (1.4.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Users/dbushuev/miniforge3/envs/neiro/lib/python3.10/site-packages (from pandas>=0.24.0->catboost) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/dbushuev/miniforge3/envs/neiro/lib/python3.10/site-packages (from pandas>=0.24.0->catboost) (2022.2.1)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /Users/dbushuev/miniforge3/envs/neiro/lib/python3.10/site-packages (from matplotlib->catboost) (3.0.9)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/dbushuev/miniforge3/envs/neiro/lib/python3.10/site-packages (from matplotlib->catboost) (21.3)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Users/dbushuev/miniforge3/envs/neiro/lib/python3.10/site-packages (from matplotlib->catboost) (9.2.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/dbushuev/miniforge3/envs/neiro/lib/python3.10/site-packages (from matplotlib->catboost) (4.37.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/dbushuev/miniforge3/envs/neiro/lib/python3.10/site-packages (from matplotlib->catboost) (0.11.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/dbushuev/miniforge3/envs/neiro/lib/python3.10/site-packages (from matplotlib->catboost) (1.4.4)\n",
      "Collecting tenacity>=6.2.0\n",
      "  Using cached tenacity-8.0.1-py3-none-any.whl (24 kB)\n",
      "Installing collected packages: tenacity, graphviz, plotly, catboost\n",
      "Successfully installed catboost-1.0.6 graphviz-0.20.1 plotly-5.10.0 tenacity-8.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0195976, 0.9804024]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat = joblib.load('CatBC.pkl')\n",
    "cat.predict_proba(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('neiro')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ff077d36edecff411963b88ef1bfe99368317a6b3a0d3848dbdbf2bfef07112c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
